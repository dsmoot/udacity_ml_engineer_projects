{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import mask as raster_mask\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "from shapely import speedups\n",
    "\n",
    "speedups.disable()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sizes = utils.get_grid_sizes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure\n",
    "\n",
    "\"train\" folder will contain one numpy mask for each classtype for every train image (train_y) and an adjusted numpy array for every 16 band raster file (train_X).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_path = os.path.join('train','train_X')\n",
    "train_y_path = os.path.join('train','train_y')\n",
    "train_path = 'train'\n",
    "\n",
    "train_dirs = [train_path,train_X_path,train_y_path]\n",
    "\n",
    "for directory in train_dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Prepare and scale train polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this will be the standard image size for training & testing\n",
    "base_size = 835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt_train = pd.read_csv('train_wkt_v4.csv')\n",
    "wkt_train['MultipolygonWKT'] = wkt_train['MultipolygonWKT'].apply(shapely.wkt.loads)\n",
    "\n",
    "train_gpd = gpd.GeoDataFrame(wkt_train,geometry='MultipolygonWKT')\n",
    "train_gpd.rename({'MultipolygonWKT':'geometry'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_h_w(src):\n",
    "    w = src.height\n",
    "    h = src.width\n",
    "\n",
    "    return w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H_W_scalers(w,H):\n",
    "    W = w**2 / (w+1)\n",
    "    H = h**2 / (h+1)\n",
    "    return W,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mask(w,h,exterior,interior,classtype):\n",
    "#     img_mask = np.zeros((w,h), np.uint8)\n",
    "#     cv2.fillPoly((w,h), exterior, classtype)\n",
    "#     if len(interior) > 0:\n",
    "#         cv2.fillPoly((w,h), interior, 0)\n",
    "#     return img_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gpd['dummy_geo'] = 0\n",
    "train_gpd['dummy_geo'] = train_gpd['dummy_geo'].astype('object')\n",
    "train_ids = train_gpd['ImageId'].unique()\n",
    "\n",
    "raster_dict = {}\n",
    "img_shape = (base_size,base_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\gis_test\\lib\\site-packages\\rasterio\\__init__.py:221: NotGeoreferencedWarning: Dataset has no geotransform set. The identity matrix may be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b93564065a5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mtrain_gpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_geometry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dummy_geo'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mtrain_gpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'geometry'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mtrain_gpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_gdf_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.geojson'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGeoJSON\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "for image_id in train_ids:\n",
    "    img = rasterio.open(os.path.join('three_band',image_id+'.tif'))\n",
    "    w, h = get_src_h_w(img)\n",
    "#     w, h = img_shape\n",
    "    W, H = get_H_W_scalers(h,w)\n",
    "    # store w, h in a dictionary for sixteen band rasters\n",
    "    \n",
    "    raster_dict[image_id] = (w,h)\n",
    "    \n",
    "    xmax, ymax = utils.get_image_max(image_id, grid_sizes)\n",
    "    \n",
    "    for index, row in train_gpd.loc[train_gpd['ImageId']==image_id].iterrows():\n",
    "        classtype = row['ClassType']\n",
    "        geo = row['geometry']\n",
    "        if str(geo) == \"GEOMETRY COLLECTION EMPTY\" or str(geo) == 'MULTIPOLYGON EMPTY':\n",
    "            train_gpd.at[index,'dummy_geo'] = np.nan\n",
    "            mask = np.zeros((img_shape),np.uint8)\n",
    "\n",
    "        else:\n",
    "            ### scale polygons\n",
    "            polys = []\n",
    "            for poly in geo:\n",
    "\n",
    "                x_ext,y_ext = np.array(poly.exterior.coords.xy[0]), np.array(poly.exterior.coords.xy[1])\n",
    "                exterior = utils.convert_xy_to_raster(x_ext,y_ext,xmax,ymax,W,H)\n",
    "                interiors = []\n",
    "                for interior in poly.interiors:\n",
    "                    x_int, y_int = np.array(interior.coords.xy[0]),np.array(interior.coords.xy[1])\n",
    "                    interiors.append(utils.convert_xy_to_raster(x_int, y_int,xmax,ymax,W,H))\n",
    "\n",
    "                scaled_poly = shapely.geometry.Polygon(exterior,interiors)\n",
    "\n",
    "                polys.append(scaled_poly)\n",
    "\n",
    "            polygon_val = shapely.geometry.MultiPolygon(polys)\n",
    "            train_gpd.at[index,'dummy_geo'] = polygon_val\n",
    "            ### get polygon mask\n",
    "#             print(image_id,classtype)\n",
    "#             mask = get_mask(w,h,exterior,interiors,classtype)\n",
    "            mask = raster_mask.mask(img,polygon_val,all_touched=True)[0][0]\n",
    "            resized_mask = resize(mask,img_shape,anti_aliasing=False)\n",
    "            mask = np.where(resized_mask==np.min(resized_mask),0,1)\n",
    "        \n",
    "        ### save mask\n",
    "        classtype = row['ClassType']\n",
    "        np.save(os.path.join(train_y_path,image_id+\"_\"+str(classtype)),mask)\n",
    "    img.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gpd.set_geometry('dummy_geo',inplace=True)\n",
    "train_gpd.drop('geometry',axis=1,inplace=True)\n",
    "train_gpd.to_file('train_gdf_'+str(img_shape[0])+'.geojson',driver=GeoJSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Create X_train, X_label\n",
    "\n",
    "X_train will be the combined 16 - band images.\n",
    "X_label will be a mask of the polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster dict created in previous step to get the h and w of the thirteen band images. Keys = image id, values = (w,h) tuple\n",
    "\n",
    "band_suffix = [\"P\",\"M\",\"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the tags in the sixteen band rasters, we know that P is panchromatic (band 1), M is multispectral (bands 2 - 9), and A is SWIR (bands 10-17). We'll read each image into a numpy array and rename the bands accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in train_ids:\n",
    "#     w,h = raster_dict[image_id]\n",
    "    array_list = []\n",
    "    for band in band_suffix:\n",
    "        img = rasterio.open(os.path.join('sixteen_band',image_id+\"_\"+band+\".tif\"))\n",
    "        scaled_img = img.read(out_shape=(img_shape[0],img_shape[1]))\n",
    "        array_list.append(scaled_img)\n",
    "        img.close()\n",
    "    train_X = np.concatenate(array_list)\n",
    "    np.save(os.path.join(train_X_path,image_id),train_X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove train dataframe to save memory\n",
    "train_gpd=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.load(os.path.join(train_X_path,train_ids[0]+\".npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 835, 835)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.load(os.path.join(train_y_path,train_ids[0]+\"_1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(835, 835)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "\n",
    "train_imgs = train_ids[:20]\n",
    "test_imgs = train_ids[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test: Class 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "# from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def jaccard_coef(y_true, y_pred):\n",
    "#     # __author__ = Vladimir Iglovikov\n",
    "#     intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "#     sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "#     jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "#     return K.mean(jac)\n",
    "\n",
    "\n",
    "# def jaccard_coef_int(y_true, y_pred):\n",
    "#     # __author__ = Vladimir Iglovikov\n",
    "#     y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "#     intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "#     sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "#     jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "#     return K.mean(jac)\n",
    "\n",
    "# def get_unet():\n",
    "#     inputs = Input((17, base_size, base_size))\n",
    "#     conv1 = Convolution2D(32, 3, 3, activation='relu')(inputs)\n",
    "#     conv1 = Convolution2D(32, 3, 3, activation='relu')(conv1)\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "#     conv2 = Convolution2D(64, 3, 3, activation='relu')(pool1)\n",
    "#     conv2 = Convolution2D(64, 3, 3, activation='relu')(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "#     conv3 = Convolution2D(128, 3, 3, activation='relu')(pool2)\n",
    "#     conv3 = Convolution2D(128, 3, 3, activation='relu')(conv3)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "#     conv4 = Convolution2D(256, 3, 3, activation='relu')(pool3)\n",
    "#     conv4 = Convolution2D(256, 3, 3, activation='relu')(conv4)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "#     conv5 = Convolution2D(512, 3, 3, activation='relu')(pool4)\n",
    "#     conv5 = Convolution2D(512, 3, 3, activation='relu')(conv5)\n",
    "\n",
    "#     up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "#     conv6 = Convolution2D(256, 3, 3, activation='relu')(up6)\n",
    "#     conv6 = Convolution2D(256, 3, 3, activation='relu')(conv6)\n",
    "\n",
    "#     up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "#     conv7 = Convolution2D(128, 3, 3, activation='relu')(up7)\n",
    "#     conv7 = Convolution2D(128, 3, 3, activation='relu')(conv7)\n",
    "\n",
    "#     up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "#     conv8 = Convolution2D(64, 3, 3, activation='relu')(up8)\n",
    "#     conv8 = Convolution2D(64, 3, 3, activation='relu')(conv8)\n",
    "\n",
    "#     up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "#     conv9 = Convolution2D(32, 3, 3, activation='relu')(up9)\n",
    "#     conv9 = Convolution2D(32, 3, 3, activation='relu')(conv9)\n",
    "\n",
    "#     conv10 = Convolution2D(N_Cls, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "#     model = Model(input=inputs, output=conv10)\n",
    "#     model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(classtype,train_ids,batch_size=5):\n",
    "    while True:\n",
    "        batch = np.random.choice(train_ids, size = batch_size)\n",
    "        X_arr = []\n",
    "        y_arr = []\n",
    "        for train_id in batch:\n",
    "            X = np.load(os.path.join(train_X_path,train_id+\".npy\"))\n",
    "            y = np.load(os.path.join(train_y_path,train_id+\"_\"+str(classtype)+\".npy\"))\n",
    "            \n",
    "            X_arr.append(X)\n",
    "            y_arr.append(y)\n",
    "        \n",
    "        batch_X = np.array(X_arr)\n",
    "        batch_y = np.array(y_arr)\n",
    "        yield (X, y)\n",
    "                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_generator = load_train(1,train_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "\n",
    "###  alternatively?\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "img_generator = train_datagen.flow_from_directory(\n",
    "        's2cloudless_imagery',\n",
    "        target_size=(512, 512),\n",
    "        batch_size=len(images),\n",
    "        class_mode=None, seed=111, shuffle=False)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,    \n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "mask_generator = test_datagen.flow_from_directory(\n",
    "        's2cloudless_label_imagery',\n",
    "        target_size=(512, 512),\n",
    "        batch_size=len(images),\n",
    "        class_mode=None, seed=111, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(classtype):\n",
    "    print(\"start train net\")\n",
    "\n",
    "#     x_trn, y_trn = get_patches(img, msk)\n",
    "\n",
    "    model = get_unet()\n",
    "#     model.load_weights('weights/unet_10_jk0.7878')\n",
    "#     model_checkpoint = ModelCheckpoint('weights/unet_tmp.hdf5', monitor='loss', save_best_only=True)\n",
    "    for i in range(1):\n",
    "        model.fit_generator(load_train(classtype), batch_size=64, nb_epoch=1, verbose=1, shuffle=True,\n",
    "                  #callbacks=[model_checkpoint], \n",
    "                  validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "        score, trs = calc_jacc(model)\n",
    "        print('val jk', score)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train net\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](conv2d_1/Identity)' with input shapes: [?,1,92,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1653\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](conv2d_1/Identity)' with input shapes: [?,1,92,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c3d84fe948ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-ecd995f79945>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(classtype)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     x_trn, y_trn = get_patches(img, msk)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#     model.load_weights('weights/unet_10_jk0.7878')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     model_checkpoint = ModelCheckpoint('weights/unet_tmp.hdf5', monitor='loss', save_best_only=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-7f99366931dd>\u001b[0m in \u001b[0;36mget_unet\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mpool1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    289\u001b[0m       \u001b[0mpool_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m       \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m     outputs = self.pool_function(\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[0;32m   3921\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ksize cannot be zero.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3923\u001b[1;33m     return gen_nn_ops.max_pool(\n\u001b[0m\u001b[0;32m   3924\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5232\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"NHWC\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5233\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5234\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   5235\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5236\u001b[0m                    data_format=data_format, name=name)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3317\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3318\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3319\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3320\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3321\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1814\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1816\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   1817\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](conv2d_1/Identity)' with input shapes: [?,1,92,32]."
     ]
    }
   ],
   "source": [
    "train_net(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import random\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_class_polygons(train_df, imageId, class_type):\n",
    "    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n",
    "    multipoly_def = df_image[df_image.ClassType == class_type].MultipolygonWKT\n",
    "    polygonList = None\n",
    "    if len(multipoly_def) > 0:\n",
    "        assert len(multipoly_def) == 1\n",
    "        polygonList = wkt_loads(multipoly_def.values[0])\n",
    "    return polygonList\n",
    "\n",
    "\n",
    "def _get_and_convert_contours(polygonList, raster_img_size, xymax):\n",
    "    perim_list = []\n",
    "    interior_list = []\n",
    "    if polygonList is None:\n",
    "        return None\n",
    "    for k in range(len(polygonList)):\n",
    "        poly = polygonList[k]\n",
    "        perim = np.array(list(poly.exterior.coords))\n",
    "        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n",
    "        perim_list.append(perim_c)\n",
    "        for pi in poly.interiors:\n",
    "            interior = np.array(list(pi.coords))\n",
    "            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n",
    "            interior_list.append(interior_c)\n",
    "    return perim_list, interior_list\n",
    "\n",
    "\n",
    "def _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n",
    "    img_mask = np.zeros(raster_img_size, np.int8)\n",
    "    if contours is None:\n",
    "        return img_mask\n",
    "    perim_list, interior_list = contours\n",
    "    cv2.fillPoly(img_mask, perim_list, class_value)\n",
    "    cv2.fillPoly(img_mask, interior_list, 0)\n",
    "    return img_mask\n",
    "\n",
    "\n",
    "def mask_to_polygons_layer(mask):\n",
    "    all_polygons = []\n",
    "    for shape, value in features.shapes(mask.astype(np.int16), mask=(mask == 1), transform=rasterio.Affine(1.0, 0, 0, 0, 1.0, 0)):\n",
    "\n",
    "        all_polygons.append(shapely.geometry.shape(shape))\n",
    "\n",
    "    all_polygons = shapely.geometry.MultiPolygon(all_polygons)\n",
    "    if not all_polygons.is_valid:\n",
    "        all_polygons = all_polygons.buffer(0)\n",
    "        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
    "        # need to keep it a Multi throughout\n",
    "        if all_polygons.type == 'Polygon':\n",
    "            all_polygons = shapely.geometry.MultiPolygon([all_polygons])\n",
    "    return all_polygons\n",
    "\n",
    "\n",
    "def generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda, wkt_list_pandas):\n",
    "    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n",
    "    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n",
    "    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n",
    "    mask = _plot_mask_from_contours(raster_size, contours, 1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def calculate_score_mask(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function calculate jaccard score for real vs mask\n",
    "\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_mask_channels = y_true.shape[0]\n",
    "\n",
    "    result = np.ones(num_mask_channels)\n",
    "\n",
    "    for mask_channel in range(num_mask_channels):\n",
    "        intersection = np.dot(y_true[mask_channel, ...].flatten(), y_pred[mask_channel, ...].flatten())\n",
    "        _sum = y_true[mask_channel, ...].sum() + y_pred[mask_channel, ...].sum()\n",
    "        if _sum - intersection != 0:\n",
    "            result[mask_channel] = intersection / (_sum - intersection)\n",
    "    return np.mean(result)\n",
    "\n",
    "\n",
    "def mask2polygons(mask, image_id):\n",
    "    \"\"\"\n",
    "\n",
    "    :param mask:\n",
    "    :return: list of the type: [Polygons_class_1, Polygons_class_2]\n",
    "    \"\"\"\n",
    "    W = mask.shape[1]\n",
    "    H = mask.shape[2]\n",
    "\n",
    "    num_mask_channels = mask.shape[0]\n",
    "\n",
    "    x_max = gs.loc[gs['ImageId'] == image_id, 'Xmax'].values[0]\n",
    "    y_min = gs.loc[gs['ImageId'] == image_id, 'Ymin'].values[0]\n",
    "\n",
    "    W_ = W * (W / (W + 1))\n",
    "    H_ = H * (H / (H + 1))\n",
    "\n",
    "    x_scaler = W_ / x_max\n",
    "    y_scaler = H_ / y_min\n",
    "\n",
    "    x_scaler = 1 / x_scaler\n",
    "    y_scaler = 1 / y_scaler\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for mask_channel in range(num_mask_channels):\n",
    "        polygons = mask_to_polygons_layer(mask[mask_channel])\n",
    "\n",
    "        polygons = shapely.affinity.scale(polygons, xfact=x_scaler, yfact=y_scaler, origin=(0, 0, 0))\n",
    "\n",
    "        if not polygons.is_valid:\n",
    "            polygons = polygons.buffer(0)\n",
    "            # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
    "            # need to keep it a Multi throughout\n",
    "            polygons = shapely.geometry.MultiPolygon([polygons])\n",
    "\n",
    "        result += [str(polygons)]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def polygons2mask(polygons, width, height, image_id):\n",
    "    xymax = _get_xmax_ymin(gs, image_id)\n",
    "\n",
    "    mask = np.zeros((len(polygons), width, height))\n",
    "\n",
    "    for i, p in enumerate(polygons):\n",
    "        polygon_list = wkt_loads(p)\n",
    "        if polygon_list.length == 0:\n",
    "            continue\n",
    "        contours = _get_and_convert_contours(polygon_list, (width, height), xymax)\n",
    "        mask[i] = _plot_mask_from_contours((width, height), contours, 1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def generate_mask(image_id, width, height, num_mask_channels=10):\n",
    "    mask = np.zeros((num_mask_channels, width, height))\n",
    "\n",
    "    for mask_channel in range(num_mask_channels):\n",
    "        mask[mask_channel, :, :] = generate_mask_for_image_and_class((width, height), image_id, mask_channel + 1, gs, train_wkt)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def calculate_polygon_match(image_id, num_mask_channels=10):\n",
    "    \"\"\"\n",
    "    calculates jaccard index between before poly and after poly\n",
    "\n",
    "    Ideally should be 1\n",
    "\n",
    "    :param image_id:\n",
    "    :param num_mask_channels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    image = tiff.imread(os.path.join(data_path, 'three_band', image_id + '.tif'))\n",
    "\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[2]\n",
    "\n",
    "    mask_before = generate_mask(image_id, width, height, num_mask_channels=num_mask_channels)\n",
    "\n",
    "    polygons = mask2polygons(mask_before, image_id)\n",
    "    predicted_mask = polygons2mask(polygons, width, height, image_id)\n",
    "\n",
    "    mask = generate_mask(image_id, width, height)\n",
    "\n",
    "    return calculate_score_mask(mask, predicted_mask)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for image_id in train_wkt['ImageId'].unique():\n",
    "        print(image_id, calculate_polygon_match(image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
